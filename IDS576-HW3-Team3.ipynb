{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDS 576 - Assignment 3\n",
    "10/20/2019\n",
    "#### Team 3:\n",
    "Scott Brewer (sbrewe5@uic.edu)  \n",
    "Rahul Shukla (rshukl4@uic.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNN for Language Modeling (40pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(x):\n",
    "    res = []\n",
    "    n_grams = list(zip(*[x[i:] for i in range(3)]))\n",
    "    for n_gram in n_grams:\n",
    "        res.append(' '.join(n_gram))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data, datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': [\"I don't know\", \"don't know who\", 'know who could', 'who could find', 'could find fault', 'find fault with', 'fault with a', 'with a simply', 'a simply human', 'simply human and', 'human and funny', 'and funny film', 'funny film like', 'film like this', 'like this with', 'this with lots', 'with lots of', 'lots of delights', 'of delights for', 'delights for your', 'for your heart.', 'your heart. I', 'heart. I enjoyed', 'I enjoyed each', 'enjoyed each minute', 'each minute of', 'minute of it', 'of it and', 'it and guessed', 'and guessed the', 'guessed the ending', 'the ending half', 'ending half way', 'half way through', 'way through the', 'through the movie', 'the movie --', 'movie -- but', '-- but that', 'but that did', 'that did not', 'did not disappoint', 'not disappoint me', 'disappoint me at', 'me at all.', 'at all. It', 'all. It will', 'It will not', 'will not only', 'not only touch', 'only touch your', 'touch your heart', 'your heart but', \"heart but it's\", \"but it's such\", \"it's such a\", 'such a good', 'a good family', 'good family friendly', 'family friendly film--we', 'friendly film--we need', 'film--we need many', 'need many more', 'many more like', 'more like these!'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "##############importing imdb daasets#############\n",
    "TEXT = data.Field(preprocessing=generate_trigrams)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT,LABEL)\n",
    "print(vars(train_data.examples[0]))\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED),split_ratio=0.9)\n",
    "TEXT.build_vocab(train_data)\n",
    "dictionary = dict(TEXT.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov = pd.DataFrame.from_dict(dictionary,orient=\"index\")\n",
    "markov = markov.reset_index()\n",
    "markov.columns = ['trigrams','cnt']\n",
    "markov['bigram'] =markov.trigrams.apply(lambda x: \" \".join(x.split(' ')[:2]))\n",
    "markov['target'] =markov.trigrams.apply(lambda x: x.split(' ')[2])\n",
    "inp_cnt = pd.DataFrame(markov.groupby(\"bigram\",as_index=False)[\"cnt\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.b. Change the output appropriately in ‘Simple Sentiment Analysis.ipynb’ to build an LSTM based language model. Plot the training performance as a function of epochs/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field()\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['I', \"don't\", 'know', 'who', 'could', 'find', 'fault', 'with', 'a', 'simply', 'human', 'and', 'funny', 'film', 'like', 'this', 'with', 'lots', 'of', 'delights', 'for', 'your', 'heart.', 'I', 'enjoyed', 'each', 'minute', 'of', 'it', 'and', 'guessed', 'the', 'ending', 'half', 'way', 'through', 'the', 'movie', '--', 'but', 'that', 'did', 'not', 'disappoint', 'me', 'at', 'all.', 'It', 'will', 'not', 'only', 'touch', 'your', 'heart', 'but', \"it's\", 'such', 'a', 'good', 'family', 'friendly', 'film--we', 'need', 'many', 'more', 'like', 'these!'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED),split_ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 6250\n",
      "Number of validation examples: 18750\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=1000)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 1002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim,BATCH_SIZE,output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden,cell) = self.rnn(embedded)\n",
    "        dim = output.size()\n",
    "        output = output.view(-1, output.shape[2])\n",
    "        output1 = F.log_softmax(output,dim=1)\n",
    "        \n",
    "        if BATCH_SIZE==dim[1]:\n",
    "            output1 = output1.view(-1,OUTPUT_DIM,BATCH_SIZE)\n",
    "        else:\n",
    "            output1 = output1.view(dim[1],OUTPUT_DIM,-1)\n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]       \n",
    "        return output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = len(TEXT.vocab)\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM,BATCH_SIZE,OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
    "criterion = nn.NLLLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion,BATCH_SIZE):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_label_count = 0 \n",
    "    loss=0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()   \n",
    "        predictions = model(batch.text)\n",
    "\n",
    "        dim = predictions.size()\n",
    "        if dim[2] !=BATCH_SIZE:\n",
    "            BATCH_SIZE = dim[2]\n",
    "            \n",
    "        pad = torch.tensor([1]*BATCH_SIZE,device=\"cuda:0\").view(BATCH_SIZE,-1)\n",
    "        _,preds = torch.max(predictions,1)\n",
    "        labels = batch.text.view(-1,BATCH_SIZE)\n",
    "        labels = labels[1:]\n",
    "        pad = torch.tensor([1]*BATCH_SIZE,device=\"cuda:0\").view(-1,BATCH_SIZE)\n",
    "        labels = torch.cat((labels,pad),0)\n",
    "        loss = criterion(predictions,labels)\n",
    "        acc = torch.sum(preds == labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_label_count+= labels.numel()\n",
    "        \n",
    "    return epoch_loss / len(iterator) , (epoch_acc /epoch_label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 5.949 | Train Acc: 9.33% \n",
      "| Epoch: 02 | Train Loss: 5.609 | Train Acc: 9.76% \n",
      "| Epoch: 03 | Train Loss: 5.593 | Train Acc: 9.38% \n",
      "| Epoch: 04 | Train Loss: 5.597 | Train Acc: 9.03% \n",
      "| Epoch: 05 | Train Loss: 5.599 | Train Acc: 8.99% \n",
      "| Epoch: 06 | Train Loss: 5.596 | Train Acc: 8.79% \n",
      "| Epoch: 07 | Train Loss: 5.597 | Train Acc: 9.14% \n",
      "| Epoch: 08 | Train Loss: 5.599 | Train Acc: 8.97% \n",
      "| Epoch: 09 | Train Loss: 5.599 | Train Acc: 9.69% \n",
      "| Epoch: 10 | Train Loss: 5.593 | Train Acc: 9.26% \n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss,train_acc = train(model, train_iterator, optimizer, criterion,BATCH_SIZE)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% ')#| Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.title(\"Training Performane by EPOCHS - 1000 words 25% training size\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. For each model, describe the key design choices made. Briefly mention how each choice influences training time and generative quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov model we went with the trigrams and there was no difficulty in calculating the probabilities and prediction.\n",
    "\n",
    "For LSTM there was an input layer followed by embedding then lstm layer. The input was the tokenized text and output also the tokenized text offsetted by 1 place. Ex) if input is {This,is,my,favorite,movie} then output is {is,my,favorite,movie}\n",
    "\n",
    "We took 25% training data with max 1000 words with batch size 10 to train our lstm model.\n",
    "If we increased the number of words then the model couldn't be loaded into the gpu as there was insufficient memory\n",
    "If we increased the training data to higher percentage say 50% or 80% then notebook got disconnected from the server randomly. This error didn't go when we tried to run the code as standalone .py file instead of a python notebook\n",
    "When we reduced the batch size to 1 then model took longer time to train and when we increased it to 64 then there was memory error once again. We settled at Batch Size 10\n",
    "Due to this limited training size and words the quality of sentence formed by predicition was affected considerably.The prediction didn't give out a coherent sentence as we would have liked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. For each model, starting with the phrase ”My favorite movie ”, sample the next few words and create a 20 word generated review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Review 1: (20) my favorite movie Dawn of the cave the siblings intended to fool Coburn with PAT GARRETT & BILLY THE KID\n",
      "\n",
      "Generated Review 2: (20) my favorite movie (next to Ranma)... and probably saying hello to Oshii's creation \"superlivemation\": not quite at the worlds described\n",
      "\n",
      "Generated Review 3: (20) my favorite movie growing up, you can drive Grandpa's car. He can't trust anyone for a self-confessed b-grade horror) and\n",
      "\n",
      "Generated Review 4: (20) my favorite movie he plays Wilhelm Grimm, a sad day in time. We never learn his true colors--enslaving women, oppressing\n",
      "\n",
      "Generated Review 5: (20) my favorite movie at all!<br /><br />He falls victim to stereotypical male vs. female characters here are better played, and\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(sentence,no_preds,prediction_length):\n",
    "    prediction_length -= len(sentence.split(\" \")) \n",
    "    for j in range(0,no_preds):\n",
    "        pred_sentence = sentence\n",
    "        bi = \" \".join(pred_sentence.split(\" \")[1:])\n",
    "        for i in range(0,prediction_length):\n",
    "            poss_pred = np.array(markov.target[markov.bigram==bi])\n",
    "            scores = np.array(markov.cnt[markov.bigram==bi])\n",
    "            length = inp_cnt.cnt[inp_cnt.bigram==bi]\n",
    "            probs = scores/length.iloc[0]\n",
    "            pred = random.choice(list(enumerate(probs)))[0]\n",
    "            pred = poss_pred[pred]\n",
    "            pred_sentence = pred_sentence + \" \" + pred\n",
    "            bi = \" \".join([bi.split(\" \")[1],pred])\n",
    "        pred_length = len(pred_sentence.split(sep=' '))\n",
    "        print(f\"Generated Review {str(j+1)}: ({pred_length}) {pred_sentence}\\n\")\n",
    "        \n",
    "generate_sentence(\"my favorite movie\",5,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Review 1: (20)  my favorite movie looking (and seeing I me I My films between least While course American give there nothing\n",
      "\n",
      "Generated Review 2: (20)  my favorite movie favorite all might last only lot once times stupid around looking as short old acting worth\n",
      "\n",
      "Generated Review 3: (20)  my favorite movie between women as time such performance Of someone school For one DVD able person At point\n",
      "\n",
      "Generated Review 4: (20)  my favorite movie very help lot time never movie The To goes isn't father enjoyed definitely />I though classic\n",
      "\n",
      "Generated Review 5: (20)  my favorite movie film, movies His will pretty gave find TV most To father quite on life several that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    inp =torch.tensor([[TEXT.vocab.stoi[\"my\"]],[TEXT.vocab.stoi[\"favorite\"]],[TEXT.vocab.stoi[\"movie\"]]],device=\"cuda:0\")\n",
    "    for i in range(16):\n",
    "        op = model(inp)\n",
    "        op = op.squeeze(0)\n",
    "        op = op[:,op.size()[1]-1].detach().cpu().numpy()\n",
    "        op = np.sort(op)[::-1]\n",
    "        op = op[:500] \n",
    "        new_inp = torch.tensor(np.where(op==np.random.choice(op,1)),device=\"cuda:0\")\n",
    "        inp = torch.cat((inp,new_inp))\n",
    "    \n",
    "    generated_text = \"\"\n",
    "    for val in inp:\n",
    "        generated_text = generated_text + \" \" + TEXT.vocab.itos[val]\n",
    "    gen_length = len(generated_text.split(sep=' '))\n",
    "    print(f\"Generated Review {str(j+1)}: ({gen_length}) {generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequence to Sequence Model for Translation (40pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Translation with a Sequence to Sequence Network and Attention\n",
    "*************************************************************\n",
    "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_  \n",
    "Modified by Scott Brewer for IDS576 HW3 Q2 assignment.\n",
    "\n",
    "In this project we will be teaching a neural network to translate from\n",
    "French to English. (shifted to Italian)\n",
    "\n",
    "... to varying degrees of success.\n",
    "\n",
    "This is made possible by the simple but powerful idea of the `sequence\n",
    "to sequence network <https://arxiv.org/abs/1409.3215>`__, in which two\n",
    "recurrent neural networks work together to transform one sequence to\n",
    "another. An encoder network condenses an input sequence into a vector,\n",
    "and a decoder network unfolds that vector into a new sequence.\n",
    "\n",
    "To improve upon this model we'll use an `attention\n",
    "mechanism <https://arxiv.org/abs/1409.0473>`__, which lets the decoder\n",
    "learn to focus over a specific range of the input sequence.\n",
    "\n",
    "**Recommended Reading:**\n",
    "\n",
    "I assume you have at least installed PyTorch, know Python, and\n",
    "understand Tensors:\n",
    "\n",
    "-  https://pytorch.org/ For installation instructions\n",
    "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
    "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
    "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
    "\n",
    "\n",
    "It would also be useful to know about Sequence to Sequence networks and\n",
    "how they work:\n",
    "\n",
    "-  `Learning Phrase Representations using RNN Encoder-Decoder for\n",
    "   Statistical Machine Translation <https://arxiv.org/abs/1406.1078>`__\n",
    "-  `Sequence to Sequence Learning with Neural\n",
    "   Networks <https://arxiv.org/abs/1409.3215>`__\n",
    "-  `Neural Machine Translation by Jointly Learning to Align and\n",
    "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
    "-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>`__\n",
    "\n",
    "You will also find the previous tutorials on\n",
    ":doc:`/intermediate/char_rnn_classification_tutorial`\n",
    "and :doc:`/intermediate/char_rnn_generation_tutorial`\n",
    "helpful as those concepts are very similar to the Encoder and Decoder\n",
    "models, respectively.\n",
    "\n",
    "And for more, read the papers that introduced these topics:\n",
    "\n",
    "-  `Learning Phrase Representations using RNN Encoder-Decoder for\n",
    "   Statistical Machine Translation <https://arxiv.org/abs/1406.1078>`__\n",
    "-  `Sequence to Sequence Learning with Neural\n",
    "   Networks <https://arxiv.org/abs/1409.3215>`__\n",
    "-  `Neural Machine Translation by Jointly Learning to Align and\n",
    "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
    "-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data files\n",
    "==================\n",
    "\n",
    "The data for this project is a set of many thousands of English to\n",
    "French translation pairs.\n",
    "\n",
    "`This question on Open Data Stack\n",
    "Exchange <https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages>`__\n",
    "pointed me to the open translation site https://tatoeba.org/ which has\n",
    "downloads available at https://tatoeba.org/eng/downloads - and better\n",
    "yet, someone did the extra work of splitting language pairs into\n",
    "individual text files here: https://www.manythings.org/anki/\n",
    "\n",
    "The English to French pairs are too big to include in the repo, so\n",
    "download to ``data/eng-fra.txt`` before continuing. The file is a tab\n",
    "separated list of translation pairs:\n",
    "\n",
    "::\n",
    "\n",
    "    I am cold.    J'ai froid.\n",
    "\n",
    ".. Note::\n",
    "   Download the data from\n",
    "   `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
    "   and extract it to the current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the character encoding used in the character-level RNN\n",
    "tutorials, we will be representing each word in a language as a one-hot\n",
    "vector, or giant vector of zeros except for a single one (at the index\n",
    "of the word). Compared to the dozens of characters that might exist in a\n",
    "language, there are many many more words, so the encoding vector is much\n",
    "larger. We will however cheat a bit and trim the data to only use a few\n",
    "thousand words per language.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/word-encoding.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a unique index per word to use as the inputs and targets of\n",
    "the networks later. To keep track of all this we will use a helper class\n",
    "called ``Lang`` which has word → index (``word2index``) and index → word\n",
    "(``index2word``) dictionaries, as well as a count of each word\n",
    "``word2count`` to use to later replace rare words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<SOS>\": 0,\"<EOS>\": 1}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<SOS>\", 1: \"<EOS>\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are all in Unicode, to simplify we will turn Unicode\n",
    "characters to ASCII, make everything lowercase, and trim most\n",
    "punctuation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split\n",
    "lines into pairs. The files are all English → Other Language, so if we\n",
    "want to translate from Other Language → English I added the ``reverse``\n",
    "flag to reverse the pairs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are a *lot* of example sentences and we want to train\n",
    "something quickly, we'll trim the data set to only relatively short and\n",
    "simple sentences. Here the maximum length is 10 words (that includes\n",
    "ending punctuation) and we're filtering to sentences that translate to\n",
    "the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n",
    "earlier).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "SEED = 0\n",
    "\n",
    "vocab_filter = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p, reverse = False):\n",
    "    if reverse == True:\n",
    "        return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "                len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "                p[1].startswith(vocab_filter)\n",
    "    else:\n",
    "        return len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "                len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "                p[0].startswith(vocab_filter)\n",
    "\n",
    "\n",
    "def filterPairs(pairs, reverse = False):\n",
    "    return [pair for pair in pairs if filterPair(pair, reverse=reverse)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "-  Read text file and split into lines, split lines into pairs\n",
    "-  Normalize text, filter by length and content\n",
    "-  Make word lists from sentences in pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs, reverse=reverse)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    # Subtract 2 to remove SOS and EOS from count\n",
    "    print(input_lang.name, input_lang.n_words-2)\n",
    "    print(output_lang.name, output_lang.n_words-2)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Training Data\n",
    "-----------------------\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the\n",
    "words in the input sentence) and target tensor (indexes of the words in\n",
    "the target sentence). While creating these vectors we will append the\n",
    "EOS token to both sequences. We then combine all tensors into a single tensor for memory effieciency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ') if word != '<EOS>']\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "# Below was intended to send a single tensor of index pairs to the gpu and then to iterate over it\n",
    "# Unfortunately, the zero buffering in the tensor of shorter sentences degraded performance\n",
    "# So I reverted back to creating a list of tensors for iteration, thus not using this function\n",
    "def tensorsForEpochs(pairs, epochs):\n",
    "    random.seed(SEED)\n",
    "    input_tensor = torch.zeros([epochs, MAX_LENGTH], dtype=torch.long, device=device)\n",
    "    target_tensor = torch.zeros([epochs, MAX_LENGTH], dtype=torch.long, device=device)\n",
    "    for epoch in range(epochs):\n",
    "        tfp_in, tfp_tgt = tensorsFromPair(random.choice(pairs))\n",
    "        input_tensor[epoch][0:len(tfp_in)] = tfp_in.flatten()\n",
    "        target_tensor[epoch][0:len(tfp_tgt)] = tfp_tgt.flatten()\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Seq2Seq Model\n",
    "=================\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
    "sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
    "seq2seq network, or `Encoder Decoder\n",
    "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
    "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
    "an input sequence and outputs a single vector, and the decoder reads\n",
    "that vector to produce an output sequence.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
    "   :alt:\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages.\n",
    "\n",
    "Consider the sentence \"Je ne suis pas le chat noir\" → \"I am not the\n",
    "black cat\". Most of the words in the input sentence have a direct\n",
    "translation in the output sentence, but are in slightly different\n",
    "orders, e.g. \"chat noir\" and \"black cat\". Because of the \"ne/pas\"\n",
    "construction there is also one more word in the input sentence. It would\n",
    "be difficult to produce a correct translation directly from the sequence\n",
    "of input words.\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the\n",
    "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
    "vector — a single point in some N dimensional space of sentences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Encoder\n",
    "-----------\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for\n",
    "every word from the input sentence. For every input word the encoder\n",
    "outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word.\n",
    "\n",
    ".. figure:: /_static/img/seq-seq-images/encoder-network.png\n",
    "   :alt:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        self.gru.flatten_parameters()\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # (1,1) is for numlayers=1, batchsize=1, shifted to randn from zeros\n",
    "        return torch.randn(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decoder\n",
    "-----------\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and\n",
    "outputs a sequence of words to create the translation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Decoder  \n",
    " \n",
    "In the simplest seq2seq decoder we use only last output of the encoder.\n",
    "This last output is sometimes called the *context vector* as it encodes\n",
    "context from the entire sequence. This context vector is used as the\n",
    "initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and\n",
    "hidden state. The initial input token is the start-of-string ``<SOS>``\n",
    "token, and the first hidden state is the context vector (the encoder's\n",
    "last hidden state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple decoder is included for reference, but never actually used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Decoder\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder,\n",
    "that single vector carries the burden of encoding the entire sentence.\n",
    "\n",
    "Attention allows the decoder network to \"focus\" on a different part of\n",
    "the encoder's outputs for every step of the decoder's own outputs. First\n",
    "we calculate a set of *attention weights*. These will be multiplied by\n",
    "the encoder output vectors to create a weighted combination. The result\n",
    "(called ``attn_applied`` in the code) should contain information about\n",
    "that specific part of the input sequence, and thus help the decoder\n",
    "choose the right output words.\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward\n",
    "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
    "Because there are sentences of all sizes in the training data, to\n",
    "actually create and train this layer we have to choose a maximum\n",
    "sentence length (input length, for encoder outputs) that it can apply\n",
    "to. Sentences of the maximum length will use all the attention weights,\n",
    "while shorter sentences will only use the first few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size #256\n",
    "        self.output_size = output_size #n_words in output vocab\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length #10\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        # shifted to randn vs zeros\n",
    "        return torch.randn(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
    "  limitation by using a relative position approach. Read about \"local\n",
    "  attention\" in `Effective Approaches to Attention-based Neural Machine\n",
    "  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n",
    "\n",
    "Training\n",
    "========"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are helper functions to print time elapsed and estimated time remaining given the current time and progress %. This is also a plotting helper to plot epochs vs loss. Plotting is done with matplotlib, using the array of loss values plot_losses saved while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model\n",
    "------------------\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track\n",
    "of every output and the latest hidden state. Then the decoder is given\n",
    "the `<SOS>` token as its first input, and the last hidden state of the\n",
    "encoder as its first hidden state.\n",
    "\n",
    "\"Teacher forcing\" is the concept of using the real target outputs as\n",
    "each next input, instead of using the decoder's guess as the next input.\n",
    "Using teacher forcing causes it to converge faster but \"when the trained network is exploited, it may exhibit instability\". \n",
    "<http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf>.\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with\n",
    "coherent grammar but wander far from the correct translation -\n",
    "intuitively it has learned to represent the output grammar and can \"pick\n",
    "up\" the meaning once the teacher tells it the first few words, but it\n",
    "has not properly learned how to create the sentence from the translation\n",
    "in the first place.\n",
    "\n",
    "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
    "choose to use teacher forcing or not with a simple if statement. Turn\n",
    "\"teacher_forcing_ratio\" up to use more of it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    #input_length = input_tensor.shape\n",
    "    #target_length = target_tensor.shape\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei, token in enumerate(input_tensor):\n",
    "        #print(token, token.dtype)\n",
    "        encoder_output, encoder_hidden = encoder(token, encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    '''\n",
    "    # See below for shortened version of this section for my own understanding and better clarity\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            print(decoder_output.shape, target_tensor[di])\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            print(decoder_output.shape, target_tensor[di])\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "    '''\n",
    "    \n",
    "    for di, token in enumerate(target_tensor):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        # Recall that first input is always SOS, thus current token is always compared to pred\n",
    "        \n",
    "        # Criterion expects batch as first dim, so must unsqeeze token to mimic batch size of one\n",
    "        #loss += criterion(decoder_output, token.unsqueeze(0))\n",
    "        loss += criterion(decoder_output, token)\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing to feed current target token as next input\n",
    "            decoder_input = token \n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            # topk extracts top softmax result\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "            \n",
    "    \n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / (di+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "-  Start a timer\n",
    "-  Initialize optimizers and criterion\n",
    "-  Create set of training pairs\n",
    "-  Start empty losses array for plotting\n",
    "\n",
    "Then we call ``train`` many times and occasionally print the progress (%\n",
    "of examples, time so far, estimated time) and average loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(pairs, encoder, decoder, epochs, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    print('Building tensors...')\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(epochs)]\n",
    "    #training_pairs = tensorsForEpochs(pairs, epochs)\n",
    "    criterion = nn.NLLLoss()\n",
    "    print('Training...')\n",
    "    for epoch, training_pair in enumerate(training_pairs, 1): #range(1, epochs + 1):\n",
    "        #training_pair = training_pairs[epoch - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / epochs),\n",
    "                                         epoch, epoch / epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder's predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder's\n",
    "attention outputs for display later.\n",
    "\n",
    "We can evaluate random sentences from the training set or a batch of given sentences and print out the\n",
    "input, target, and output to make some subjective quality judgements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "    \n",
    "def evaluateRandomly(pairs, encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        \n",
    "def evaluateBatch(pairs, encoder, decoder):\n",
    "    output_pairs = []\n",
    "    for pair in pairs:\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        output_pairs.append((output_sentence, pair[0]))\n",
    "    return output_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Train the sequence to sequence model (Model 1) provided for a language pair where the output is English and the input is a language of your choice - in this case, Italian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and Evaluating\n",
    "=======================\n",
    "\n",
    "With all these helper functions in place (it looks like extra work, but\n",
    "it makes it easier to run multiple experiments) we can actually\n",
    "initialize a network and start training.\n",
    "\n",
    "Remember that the input sentences were heavily filtered. For this small\n",
    "dataset we can use relatively small networks of 256 hidden nodes and a\n",
    "single GRU layer. After about 40 minutes on a MacBook CPU (or about 20 minutes on a GPU) we'll get some\n",
    "reasonable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 331799 sentence pairs\n",
      "Trimmed to 30715 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "ita 5218\n",
      "eng 3059\n",
      "['io sono qui per aiutarti .', 'i m here to help you .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng', 'ita', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this the first time to initialize the RNNs\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tensors...\n",
      "Training...\n",
      "1m 12s (- 16m 51s) (5000 6%) 3.1204\n",
      "2m 22s (- 15m 24s) (10000 13%) 2.3709\n",
      "3m 33s (- 14m 12s) (15000 20%) 2.0159\n",
      "4m 44s (- 13m 1s) (20000 26%) 1.7784\n",
      "5m 54s (- 11m 48s) (25000 33%) 1.5506\n",
      "7m 4s (- 10m 37s) (30000 40%) 1.4001\n",
      "8m 16s (- 9m 26s) (35000 46%) 1.2681\n",
      "9m 26s (- 8m 15s) (40000 53%) 1.1758\n",
      "10m 37s (- 7m 4s) (45000 60%) 1.0728\n",
      "11m 48s (- 5m 54s) (50000 66%) 0.9720\n",
      "12m 57s (- 4m 42s) (55000 73%) 0.9143\n",
      "14m 8s (- 3m 32s) (60000 80%) 0.8631\n",
      "15m 21s (- 2m 21s) (65000 86%) 0.8163\n",
      "16m 33s (- 1m 10s) (70000 93%) 0.7393\n",
      "17m 45s (- 0m 0s) (75000 100%) 0.7192\n"
     ]
    }
   ],
   "source": [
    "# Run this to actually start the training loop, or to continue the training loop\n",
    "plot_losses = trainIters(pairs, encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, loss decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the encoder and decoder\n",
    "import pickle\n",
    "model_path = '/home/team3/IDS576/models'\n",
    "with open(model_path+'/eng-ita_encoder1.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder1, f)\n",
    "with open(model_path+'/eng-ita_attn_decoder1.pkl', 'wb') as f:\n",
    "    pickle.dump(attn_decoder1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the saved encoder and decoder\n",
    "import pickle\n",
    "model_path = '/home/team3/IDS576/models'\n",
    "with open(model_path+'/eng-ita_encoder1.pkl', 'rb') as f:\n",
    "    encoder1 = pickle.load(f)\n",
    "with open(model_path+'/eng-ita_attn_decoder1.pkl', 'rb') as f:\n",
    "    attn_decoder1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> siete noiosi .\n",
      "= you re boring .\n",
      "< you re boring . <EOS>\n",
      "\n",
      "> noi ci incontriamo con tom tra tre ore .\n",
      "= we re meeting tom in three hours .\n",
      "< we re meeting tom tom in three hours . <EOS>\n",
      "\n",
      "> lui non e americano .\n",
      "= he is not an american .\n",
      "< he is not perfect . <EOS>\n",
      "\n",
      "> non stiamo prendendo nulla .\n",
      "= we re not taking anything .\n",
      "< we re not talking anything . <EOS>\n",
      "\n",
      "> tu non sei malato .\n",
      "= you re not sick .\n",
      "< you re not sick . <EOS>\n",
      "\n",
      "> sto aspettando una lettera da tom .\n",
      "= i m waiting for a letter from tom .\n",
      "< i m waiting for a call tom . <EOS>\n",
      "\n",
      "> tu sei un ragazzo intelligente .\n",
      "= you re a bright boy .\n",
      "< you re a smart boy . <EOS>\n",
      "\n",
      "> avete ragione ovviamente .\n",
      "= you re right of course .\n",
      "< you re all right right . <EOS>\n",
      "\n",
      "> loro sono dappertutto .\n",
      "= they re everywhere .\n",
      "< they re dangerous . <EOS>\n",
      "\n",
      "> io sono ansiosa di vederlo .\n",
      "= i m anxious to see it .\n",
      "< i m anxious to see it . <EOS>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1266: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(pairs, encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Now train another model (Model 2) for the reverse (i.e., from English to the language you chose). In this model, use the GloVe 100 dimensional embeddings (see notebook 4, cell 2 for an example) while training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following GloVe loading and use code were adapted from this post https://medium.com/@martinpella/how-to-use-pre-trained-word-embeddings-in-pytorch-71ca59249f76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run once - run next cell to reload pickled files\n",
    "\n",
    "# bcolz provides columnar, chunked data containers that can be compressed either in-memory and on-disk.\n",
    "# bcolz is used here due to the size of the glove data\n",
    "import bcolz\n",
    "\n",
    "glove_path = '/home/team3/IDS576/glove'\n",
    "words = []\n",
    "idx = 0\n",
    "word2idx = {}\n",
    "\n",
    "# Initialize bcolz array on disk\n",
    "vectors = bcolz.carray(np.zeros(1), rootdir=f'{glove_path}/6B.100.dat', mode='w')\n",
    "\n",
    "# Open and parse glove file\n",
    "with open(f'{glove_path}/glove.6B.100d.txt', 'rb') as f:\n",
    "    for l in f:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word2idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = np.array(line[1:]).astype(np.float)\n",
    "        vectors.append(vect)\n",
    "\n",
    "# Write vector data to bcolz array on disk\n",
    "vectors = bcolz.carray(vectors[1:].reshape((400000, 100)), rootdir=f'{glove_path}/6B.100.dat', mode='w')\n",
    "vectors.flush()\n",
    "\n",
    "with open(f'{glove_path}/6B.100_words.pkl', 'wb') as f:\n",
    "    pickle.dump(words, f)\n",
    "    \n",
    "with open(f'{glove_path}/6B.100_idx.pkl', 'wb') as f:\n",
    "    pickle.dump(word2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to load glove data\n",
    "\n",
    "import bcolz\n",
    "\n",
    "glove_path = '/home/team3/IDS576/glove'\n",
    "vectors = bcolz.open(f'{glove_path}/6B.100.dat')[:]\n",
    "\n",
    "with open(f'{glove_path}/6B.100_words.pkl', 'rb') as f:\n",
    "    words = pickle.load(f)\n",
    "    \n",
    "with open(f'{glove_path}/6B.100_idx.pkl', 'rb') as f:\n",
    "    word2idx = pickle.load(f)\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 331799 sentence pairs\n",
      "Trimmed to 30715 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3059\n",
      "ita 5218\n",
      "['i m giving it to you .', 'te la sto dando .']\n"
     ]
    }
   ],
   "source": [
    "# import our sentences pairs and associated vocabs\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "vocab_filter = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'ita', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"<SOS>\" is not in GloVe.\n",
      "The word \"<EOS>\" is not in GloVe.\n",
      "2 words are not in GloVe.\n"
     ]
    }
   ],
   "source": [
    "# Build vocab and check it against glove\n",
    "cnt = 0\n",
    "target_vocab = input_lang.word2index\n",
    "for word in target_vocab:\n",
    "    try:\n",
    "        glove[word]\n",
    "    except:\n",
    "        print(f'The word \"{word}\" is not in GloVe.')\n",
    "        cnt += 1\n",
    "if cnt > 0:\n",
    "    print(f'{cnt} words are not in GloVe.')\n",
    "else:\n",
    "    print('All of our words are in GloVe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> not found.\n",
      "<EOS> not found.\n",
      "Words Found: 3059 out of 3061\n",
      "torch.Size([3063, 100]) torch.float64 True\n"
     ]
    }
   ],
   "source": [
    "# Set weight matrix size as vocab + 2 to account for the SOS and EOS chars in our vocab\n",
    "matrix_len = len(target_vocab) + 2\n",
    "weights_matrix = np.zeros((matrix_len, 100))\n",
    "words_found = 0\n",
    "\n",
    "# Start fill of weight matrix at 2 to account for the SOS and EOS chars in our vocab at indices 0 and 1\n",
    "for i, word in enumerate(target_vocab, 2):\n",
    "    try:\n",
    "        #print(i, word)\n",
    "        weights_matrix[i] = glove[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        print(f'{word} not found.') #weights_matrix[i] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "weights_matrix = torch.from_numpy(weights_matrix).to(device)\n",
    "print(f'Words Found: {words_found} out of {len(target_vocab)}')\n",
    "print(weights_matrix.shape, weights_matrix.dtype, weights_matrix.is_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define new encoder that will import the matrix of GloVe embeddings as the the embedding layer weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape  # vocab size x 100\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class GloveEncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, batch_size=1):\n",
    "        super(GloveEncoderRNN, self).__init__()\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        #self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, num_layers)\n",
    "\n",
    "    def forward(self, inp, hidden):\n",
    "        embedded = self.embedding(inp).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that hidden size defines the GRU size, not the number of embeddings in this model\n",
    "# Instead we use GloVe embed size of 100 as determined in the GloVe loading process\n",
    "hidden_size = 256\n",
    "encoder2 = GloveEncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder2 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tensors...\n",
      "Training...\n",
      "1m 3s (- 14m 43s) (5000 6%) 4.4445\n",
      "2m 5s (- 13m 32s) (10000 13%) 3.7412\n",
      "3m 4s (- 12m 19s) (15000 20%) 3.4956\n",
      "4m 4s (- 11m 11s) (20000 26%) 3.3069\n",
      "5m 3s (- 10m 7s) (25000 33%) 3.0956\n",
      "6m 4s (- 9m 7s) (30000 40%) 2.9651\n",
      "7m 6s (- 8m 7s) (35000 46%) 2.8522\n",
      "8m 7s (- 7m 6s) (40000 53%) 2.6898\n",
      "9m 8s (- 6m 5s) (45000 60%) 2.6049\n",
      "10m 9s (- 5m 4s) (50000 66%) 2.5045\n",
      "11m 10s (- 4m 3s) (55000 73%) 2.3931\n",
      "12m 12s (- 3m 3s) (60000 80%) 2.3193\n",
      "13m 13s (- 2m 2s) (65000 86%) 2.2641\n",
      "14m 14s (- 1m 1s) (70000 93%) 2.1512\n",
      "15m 15s (- 0m 0s) (75000 100%) 2.0936\n"
     ]
    }
   ],
   "source": [
    "# Run to train model or rerun to continue training model\n",
    "plot_losses = trainIters(pairs, encoder2, attn_decoder2, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tensors...\n",
      "Training...\n",
      "1m 11s (- 16m 36s) (5000 6%) 2.0749\n",
      "2m 18s (- 14m 58s) (10000 13%) 1.9813\n",
      "3m 25s (- 13m 40s) (15000 20%) 1.9212\n",
      "4m 32s (- 12m 30s) (20000 26%) 1.8763\n",
      "5m 41s (- 11m 23s) (25000 33%) 1.8504\n",
      "6m 49s (- 10m 13s) (30000 40%) 1.7762\n",
      "7m 56s (- 9m 4s) (35000 46%) 1.7719\n",
      "9m 4s (- 7m 56s) (40000 53%) 1.7195\n",
      "10m 11s (- 6m 47s) (45000 60%) 1.6898\n",
      "11m 19s (- 5m 39s) (50000 66%) 1.6509\n",
      "12m 27s (- 4m 31s) (55000 73%) 1.6235\n",
      "13m 35s (- 3m 23s) (60000 80%) 1.5884\n",
      "14m 43s (- 2m 15s) (65000 86%) 1.6075\n",
      "15m 51s (- 1m 7s) (70000 93%) 1.5722\n",
      "16m 57s (- 0m 0s) (75000 100%) 1.5714\n"
     ]
    }
   ],
   "source": [
    "# After running the 5 sentences, I wanted to conduct more training,\n",
    "# especially as the GloVe encoder loss is more than the base encoder\n",
    "# Warnings are set to ignore due to memory fragmentation warning after reloading a pickled model\n",
    "# The solution involves flatten_parameters in the model, but I can't get it to work.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plot_losses = trainIters(pairs, encoder2, attn_decoder2, 75000, print_every=5000)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional loss reduction is seen, but with slow progress and still not at the same loss as the original model. Adjusting the learning rate or forcing rate might help, but I'll stop here for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always save the model!\n",
    "model_path = '/home/team3/IDS576/models'\n",
    "\n",
    "with open(model_path+'/eng-ita_encoder2.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder2, f)\n",
    "with open(model_path+'/eng-ita_attn_decoder2.pkl', 'wb') as f:\n",
    "    pickle.dump(attn_decoder2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "import pickle\n",
    "model_path = '/home/team3/IDS576/models'\n",
    "\n",
    "with open(f'{model_path}/eng-ita_encoder2.pkl', 'rb') as f:\n",
    "    encoder2 = pickle.load(f)\n",
    "    \n",
    "with open(f'{model_path}/eng-ita_attn_decoder2.pkl', 'rb') as f:\n",
    "    attn_decoder2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> we re competitive .\n",
      "= noi siamo competitive .\n",
      "< noi siamo decisive . <EOS>\n",
      "\n",
      "> they re trapped .\n",
      "= sono intrappolati .\n",
      "< sono intrappolate . <EOS>\n",
      "\n",
      "> i m from boston .\n",
      "= vengo da boston .\n",
      "< io sono da boston . <EOS>\n",
      "\n",
      "> he is busy with his work .\n",
      "= lui e occupato con il suo lavoro .\n",
      "< e occupato col suo lavoro . <EOS>\n",
      "\n",
      "> i m angry with you .\n",
      "= sono arrabbiato con voi .\n",
      "< sono arrabbiato con voi . <EOS>\n",
      "\n",
      "> i m falling in love with you .\n",
      "= mi sto innamorando di voi .\n",
      "< mi sto innamorando di . . <EOS>\n",
      "\n",
      "> we re going to do our best .\n",
      "= noi faremo del nostro meglio .\n",
      "< faremo del nostro meglio . <EOS>\n",
      "\n",
      "> you re too generous .\n",
      "= sei troppo generoso .\n",
      "< lei e troppo . <EOS>\n",
      "\n",
      "> he s a true legend .\n",
      "= e una vera leggenda .\n",
      "< e un un grande . <EOS>\n",
      "\n",
      "> i m not deaf .\n",
      "= non sono sorda .\n",
      "< io non sono sordo . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluateRandomly(pairs, encoder2, attn_decoder2)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Input 5 well-formed English sentences into Model 2 and then input the resulting translated sentences into Model 1. Display all model outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pairs = [\n",
    "    ['i am always grateful for your help .', 'sono sempre grato per il tuo aiuto .'],\n",
    "    ['he s a good student .','e un bravo studente .'],\n",
    "    ['she is very bad at swimming .','lei e molto cattiva nel nuoto .'],\n",
    "    ['we love working on homework together !','ci piace lavorare insieme sui compiti !'],\n",
    "    ['they are not going to leave tomorrow .','non partiranno domani .'],\n",
    "    ['when are they working out ?', 'quando stanno lavorando ?']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> i am always grateful for your help .\n",
      "= sono sempre grato per il tuo aiuto .\n",
      "< sono sempre il suo aiuto . . <EOS>\n",
      "\n",
      "> he s a good student .\n",
      "= e un bravo studente .\n",
      "< e un bravo bravo . <EOS>\n",
      "\n",
      "> she is very bad at swimming .\n",
      "= lei e molto cattiva nel nuoto .\n",
      "< lei e molto a nuotare . <EOS>\n",
      "\n",
      "> we love working on homework together !\n",
      "= ci piace lavorare insieme sui compiti !\n",
      "< ci stiamo lavorando a vero ? <EOS>\n",
      "\n",
      "> they are not going to leave tomorrow .\n",
      "= non partiranno domani .\n",
      "< loro non stanno . <EOS>\n",
      "\n",
      "> when are they working out ?\n",
      "= quando stanno lavorando ?\n",
      "< noi stiamo lavorando . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "output_pairs = evaluateBatch(eval_pairs, encoder2, attn_decoder2)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input language is now: ita\n",
      "Output language is now: eng\n"
     ]
    }
   ],
   "source": [
    "# Swap language definitions\n",
    "input_lang, output_lang = output_lang, input_lang\n",
    "print(f'Input language is now: {input_lang.name}')\n",
    "print(f'Output language is now: {output_lang.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the output of Model 2 with Model 1 after swapping input and output languages above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> sono sempre il suo aiuto . . <EOS>\n",
      "= i am always grateful for your help .\n",
      "< i m always your help . <EOS>\n",
      "\n",
      "> e un bravo bravo . <EOS>\n",
      "= he s a good student .\n",
      "< you is a good player . <EOS>\n",
      "\n",
      "> lei e molto a nuotare . <EOS>\n",
      "= she is very bad at swimming .\n",
      "< you re very brave in swimming . <EOS>\n",
      "\n",
      "> ci stiamo lavorando a vero ? <EOS>\n",
      "= we love working on homework together !\n",
      "< we re working about you aren t you ? <EOS>\n",
      "\n",
      "> loro non stanno . <EOS>\n",
      "= they are not going to leave tomorrow .\n",
      "< they re not they . <EOS>\n",
      "\n",
      "> noi stiamo lavorando . . <EOS>\n",
      "= when are they working out ?\n",
      "< we re working . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "double_output_pairs = evaluateBatch(output_pairs, encoder1, attn_decoder1)\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While none of the sentences are anywhere close to perfect, they are at least similar to the original english! Also, we see several double periods, which isn't ideal, but might be an artifact of teacher forcing inserting a period token following another period during training.\n",
    "\n",
    "For next steps, I would retrain the both models with fewer filters and longer max length, to allow for translation of more interesting sentences and to allow more chance to train on different word constructions. Also, adding additional layers and birectionality, with a MUCH longer training time should improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
