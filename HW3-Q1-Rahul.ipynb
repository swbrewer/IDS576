{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigrams(x):\n",
    "    res = []\n",
    "    n_grams = list(zip(*[x[i:] for i in range(3)]))\n",
    "    for n_gram in n_grams:\n",
    "        res.append(' '.join(n_gram))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data, datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': [\"I don't know\", \"don't know who\", 'know who could', 'who could find', 'could find fault', 'find fault with', 'fault with a', 'with a simply', 'a simply human', 'simply human and', 'human and funny', 'and funny film', 'funny film like', 'film like this', 'like this with', 'this with lots', 'with lots of', 'lots of delights', 'of delights for', 'delights for your', 'for your heart.', 'your heart. I', 'heart. I enjoyed', 'I enjoyed each', 'enjoyed each minute', 'each minute of', 'minute of it', 'of it and', 'it and guessed', 'and guessed the', 'guessed the ending', 'the ending half', 'ending half way', 'half way through', 'way through the', 'through the movie', 'the movie --', 'movie -- but', '-- but that', 'but that did', 'that did not', 'did not disappoint', 'not disappoint me', 'disappoint me at', 'me at all.', 'at all. It', 'all. It will', 'It will not', 'will not only', 'not only touch', 'only touch your', 'touch your heart', 'your heart but', \"heart but it's\", \"but it's such\", \"it's such a\", 'such a good', 'a good family', 'good family friendly', 'family friendly film--we', 'friendly film--we need', 'film--we need many', 'need many more', 'many more like', 'more like these!'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "##############importing imdb daasets#############\n",
    "TEXT = data.Field(preprocessing=generate_trigrams)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT,LABEL)\n",
    "print(vars(train_data.examples[0]))\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED),split_ratio=0.9)\n",
    "TEXT.build_vocab(train_data)\n",
    "dictionary = dict(TEXT.vocab.freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov = pd.DataFrame.from_dict(dictionary,orient=\"index\")\n",
    "markov = markov.reset_index()\n",
    "markov.columns = ['trigrams','cnt']\n",
    "markov['bigram'] =markov.trigrams.apply(lambda x: \" \".join(x.split(' ')[:2]))\n",
    "markov['target'] =markov.trigrams.apply(lambda x: x.split(' ')[2])\n",
    "inp_cnt = pd.DataFrame(markov.groupby(\"bigram\",as_index=False)[\"cnt\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Change the output appropriately in ‘Simple Sentiment Analysis.ipynb’ to build an LSTM based language model. Plot the training performance as a function of epochs/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TEXT = data.Field()\n",
    "LABEL = data.LabelField(dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import datasets\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 25000\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['I', \"don't\", 'know', 'who', 'could', 'find', 'fault', 'with', 'a', 'simply', 'human', 'and', 'funny', 'film', 'like', 'this', 'with', 'lots', 'of', 'delights', 'for', 'your', 'heart.', 'I', 'enjoyed', 'each', 'minute', 'of', 'it', 'and', 'guessed', 'the', 'ending', 'half', 'way', 'through', 'the', 'movie', '--', 'but', 'that', 'did', 'not', 'disappoint', 'me', 'at', 'all.', 'It', 'will', 'not', 'only', 'touch', 'your', 'heart', 'but', \"it's\", 'such', 'a', 'good', 'family', 'friendly', 'film--we', 'need', 'many', 'more', 'like', 'these!'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED),split_ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 6250\n",
      "Number of validation examples: 18750\n",
      "Number of testing examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=1000)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 1002\n",
      "Unique tokens in LABEL vocabulary: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim,BATCH_SIZE,output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        embedded = self.embedding(x)\n",
    "        output, (hidden,cell) = self.rnn(embedded)\n",
    "        dim = output.size()\n",
    "        output = output.view(-1, output.shape[2])\n",
    "        output1 = F.log_softmax(output,dim=1)\n",
    "        \n",
    "        if BATCH_SIZE==dim[1]:\n",
    "            output1 = output1.view(-1,OUTPUT_DIM,BATCH_SIZE)\n",
    "        else:\n",
    "            output1 = output1.view(dim[1],OUTPUT_DIM,-1)\n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]       \n",
    "        return output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "OUTPUT_DIM = len(TEXT.vocab)\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM,BATCH_SIZE,OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
    "criterion = nn.NLLLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion,BATCH_SIZE):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_label_count = 0 \n",
    "    loss=0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()   \n",
    "        predictions = model(batch.text)\n",
    "\n",
    "        dim = predictions.size()\n",
    "        if dim[2] !=BATCH_SIZE:\n",
    "            BATCH_SIZE = dim[2]\n",
    "            \n",
    "        pad = torch.tensor([1]*BATCH_SIZE,device=\"cuda:0\").view(BATCH_SIZE,-1)\n",
    "        _,preds = torch.max(predictions,1)\n",
    "        labels = batch.text.view(-1,BATCH_SIZE)\n",
    "        labels = labels[1:]\n",
    "        pad = torch.tensor([1]*BATCH_SIZE,device=\"cuda:0\").view(-1,BATCH_SIZE)\n",
    "        labels = torch.cat((labels,pad),0)\n",
    "        loss = criterion(predictions,labels)\n",
    "        acc = torch.sum(preds == labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_label_count+= labels.numel()\n",
    "        \n",
    "    return epoch_loss / len(iterator) , (epoch_acc /epoch_label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 01 | Train Loss: 5.949 | Train Acc: 9.33% \n",
      "| Epoch: 02 | Train Loss: 5.609 | Train Acc: 9.76% \n",
      "| Epoch: 03 | Train Loss: 5.593 | Train Acc: 9.38% \n",
      "| Epoch: 04 | Train Loss: 5.597 | Train Acc: 9.03% \n",
      "| Epoch: 05 | Train Loss: 5.599 | Train Acc: 8.99% \n",
      "| Epoch: 06 | Train Loss: 5.596 | Train Acc: 8.79% \n",
      "| Epoch: 07 | Train Loss: 5.597 | Train Acc: 9.14% \n",
      "| Epoch: 08 | Train Loss: 5.599 | Train Acc: 8.97% \n",
      "| Epoch: 09 | Train Loss: 5.599 | Train Acc: 9.69% \n",
      "| Epoch: 10 | Train Loss: 5.593 | Train Acc: 9.26% \n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss,train_acc = train(model, train_iterator, optimizer, criterion,BATCH_SIZE)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% ')#| Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.title(\"Training Performane by EPOCHS - 1000 words 25% training size\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each model, describe the key design choices made. Briefly mention how each choice influences training time and generative quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov model we went with the trigrams and there was no difficulty in calculating the probabilities and prediction.\n",
    "\n",
    "For LSTM there was an input layer followed by embedding then lstm layer. The input was the tokenized text and output also the tokenized text offsetted by 1 place. Ex) if input is {This,is,my,favorite,movie} then output is {is,my,favorite,movie}\n",
    "\n",
    "We took 25% training data with max 1000 words with batch size 10 to train our lstm model.\n",
    "If we increased the number of words then the model couldn't be loaded into the gpu as there was insufficient memory\n",
    "If we increased the training data to higher percentage say 50% or 80% then notebook got disconnected from the server randomly. This error didn't go when we tried to run the code as standalone .py file instead of a python notebook\n",
    "When we reduced the batch size to 1 then model took longer time to train and when we increased it to 64 then there was memory error once again. We settled at Batch Size 10\n",
    "Due to this limited training size and words the quality of sentence formed by predicition was affected considerably.The prediction didn't give out a coherent sentence as we would have liked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For each model, starting with the phrase ”My favorite movie ”, sample the next few words and create a 20 word generated review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Review 1: (20) my favorite movie Dawn of the cave the siblings intended to fool Coburn with PAT GARRETT & BILLY THE KID\n",
      "\n",
      "Generated Review 2: (20) my favorite movie (next to Ranma)... and probably saying hello to Oshii's creation \"superlivemation\": not quite at the worlds described\n",
      "\n",
      "Generated Review 3: (20) my favorite movie growing up, you can drive Grandpa's car. He can't trust anyone for a self-confessed b-grade horror) and\n",
      "\n",
      "Generated Review 4: (20) my favorite movie he plays Wilhelm Grimm, a sad day in time. We never learn his true colors--enslaving women, oppressing\n",
      "\n",
      "Generated Review 5: (20) my favorite movie at all!<br /><br />He falls victim to stereotypical male vs. female characters here are better played, and\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_sentence(sentence,no_preds,prediction_length):\n",
    "    prediction_length -= len(sentence.split(\" \")) \n",
    "    for j in range(0,no_preds):\n",
    "        pred_sentence = sentence\n",
    "        bi = \" \".join(pred_sentence.split(\" \")[1:])\n",
    "        for i in range(0,prediction_length):\n",
    "            poss_pred = np.array(markov.target[markov.bigram==bi])\n",
    "            scores = np.array(markov.cnt[markov.bigram==bi])\n",
    "            length = inp_cnt.cnt[inp_cnt.bigram==bi]\n",
    "            probs = scores/length.iloc[0]\n",
    "            pred = random.choice(list(enumerate(probs)))[0]\n",
    "            pred = poss_pred[pred]\n",
    "            pred_sentence = pred_sentence + \" \" + pred\n",
    "            bi = \" \".join([bi.split(\" \")[1],pred])\n",
    "        pred_length = len(pred_sentence.split(sep=' '))\n",
    "        print(f\"Generated Review {str(j+1)}: ({pred_length}) {pred_sentence}\\n\")\n",
    "generate_sentence(\"my favorite movie\",5,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Review 1: (20)  my favorite movie looking (and seeing I me I My films between least While course American give there nothing\n",
      "\n",
      "Generated Review 2: (20)  my favorite movie favorite all might last only lot once times stupid around looking as short old acting worth\n",
      "\n",
      "Generated Review 3: (20)  my favorite movie between women as time such performance Of someone school For one DVD able person At point\n",
      "\n",
      "Generated Review 4: (20)  my favorite movie very help lot time never movie The To goes isn't father enjoyed definitely />I though classic\n",
      "\n",
      "Generated Review 5: (20)  my favorite movie film, movies His will pretty gave find TV most To father quite on life several that\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    inp =torch.tensor([[TEXT.vocab.stoi[\"my\"]],[TEXT.vocab.stoi[\"favorite\"]],[TEXT.vocab.stoi[\"movie\"]]],device=\"cuda:0\")\n",
    "    for i in range(16):\n",
    "        op = model(inp)\n",
    "        op = op.squeeze(0)\n",
    "        op = op[:,op.size()[1]-1].detach().cpu().numpy()\n",
    "        op = np.sort(op)[::-1]\n",
    "        op = op[:500] \n",
    "        new_inp = torch.tensor(np.where(op==np.random.choice(op,1)),device=\"cuda:0\")\n",
    "        inp = torch.cat((inp,new_inp))\n",
    "    \n",
    "    generated_text = \"\"\n",
    "    for val in inp:\n",
    "        generated_text = generated_text + \" \" + TEXT.vocab.itos[val]\n",
    "    gen_length = len(generated_text.split(sep=' '))\n",
    "    print(f\"Generated Review {str(j+1)}: ({gen_length}) {generated_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
