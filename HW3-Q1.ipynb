{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data, datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.greedy = True\n",
    "SEED = 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNN for Language Modeling (40pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Import the torchtext IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-split train and test data\n",
    "TEXT = data.Field() #default parse by spaces\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 25000, of type: <class 'torchtext.data.example.Example'>\n",
      "{'text': ['I', \"don't\", 'know', 'who', 'could', 'find', 'fault', 'with', 'a', 'simply', 'human', 'and', 'funny', 'film', 'like', 'this', 'with', 'lots', 'of', 'delights', 'for', 'your', 'heart.', 'I', 'enjoyed', 'each', 'minute', 'of', 'it', 'and', 'guessed', 'the', 'ending', 'half', 'way', 'through', 'the', 'movie', '--', 'but', 'that', 'did', 'not', 'disappoint', 'me', 'at', 'all.', 'It', 'will', 'not', 'only', 'touch', 'your', 'heart', 'but', \"it's\", 'such', 'a', 'good', 'family', 'friendly', 'film--we', 'need', 'many', 'more', 'like', 'these!'], 'label': 'pos'}\n",
      "\n",
      "Test Samples: 25000, of type: <class 'torchtext.data.example.Example'>\n",
      "{'text': ['I', 'read', 'most', 'of', 'the', 'comments', 'here', 'were', 'everybody', 'saw', 'only', 'the', 'flaws', 'of', 'the', 'movie.', 'I', 'agree,', 'the', 'director', \"it's\", 'not', 'Kuprik,', 'the', 'actors', 'are', 'not', 'Oscar', 'winners,', 'but', 'it', 'has', 'something', 'everyone', 'could', 'relate', 'to.', 'I', \"don't\", 'want', 'to', 'spoil', 'but', 'telling', 'more', 'then', 'the', 'plot', '-', 'the', 'finishing', 'of', 'school', 'and', 'the', 'trip', 'to', 'a', 'big', 'party,', 'or', 'if', 'you', 'like', 'to', 'see', 'beyond', 'the', 'metaphor,', 'is', 'choosing', 'the', 'way', 'trough', 'life.', 'Remember', 'that', 'days', 'of', 'youth?', 'the', 'days', 'when', 'you', 'or', 'our', 'friend', 'acted', 'like', 'the', 'characters?', 'Or', 'do', 'you', 'think', 'you', 'should', 'acted', 'like', 'one', 'of', 'them', 'and', 'now', 'you', 'regret', 'you', \"didn't?\", 'if', 'you', 'can', 'go', 'back', 'in', 'to', 'that', 'time', 'and', 'if', 'you', 'can', 'ask', 'yourself', 'any', 'of', 'this', 'questions', 'maybe', 'the', 'movie', \"wasn't\", 'so', 'bad.'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print('Train Samples: {}, of type: {}'.format(len(train_data), type(train_data.examples[0])))\n",
    "print(vars(train_data.examples[0]))\n",
    "print()\n",
    "print('Test Samples: {}, of type: {}'.format(len(test_data), type(test_data.examples[0])))\n",
    "print(vars(test_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 17500, of type: <class 'torchtext.data.example.Example'>\n",
      "Valid Samples: 7500, of type: <class 'torchtext.data.example.Example'>\n"
     ]
    }
   ],
   "source": [
    "# Split train data into train and validation data, default split is 70/30\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))\n",
    "print('Train Samples: {}, of type: {}'.format(len(train_data), type(train_data.examples[0])))\n",
    "print('Valid Samples: {}, of type: {}'.format(len(valid_data), type(valid_data.examples[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Build a Markov (n-gram) language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a vocabulary of most common words in the train set\n",
    "VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = VOCAB_SIZE)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['This', 'was', 'just', 'plain', 'terrible.', 'I', 'read', 'this', 'book', 'for', 'school,', 'i', 'made', 'As', 'on', 'all', 'of', 'the', 'tests,', 'and', 'to', 'see', 'it', 'like', 'this!', 'My', 'teacher', 'forced', 'me', 'and', '20', 'other', 'people', 'to', 'watch', 'it,', 'and', 'it', 'was', 'worse', 'than', 'Leonard', 'Part', '6,', 'Plan', '9', 'from', 'Outer', 'Space,', 'and', 'Hudson', 'Hawk', 'put', 'together.', 'The', 'thing', 'that', 'made', 'this', 'film', 'so', 'terrible', 'was', 'enough', 'reasons', 'to', 'want', 'to', 'kill', 'yourself', 'over.', 'First', 'of', 'all,', 'it', 'was', 'made', 'on', 'Hallmark.', 'Second,', 'the', 'acting', 'was', 'terrible.', 'Third,', 'it', 'was', 'like', 'completely', 'different', 'from', 'the', 'book.', 'Literally,', 'it', 'was', 'so', 'bad', 'I', 'asked', 'myself', 'to', 'be', 'excused.', 'Basically,', 'I', 'would', 'rather', 'watch', 'Basic', 'Instinct', '2', 'than', 'watch', 'this.', 'Take', 'my', 'advice,', \"don't\", 'watch', 'this', 'film.', 'No', 'one', 'would', 'want', 'to', 'watch', 'this.', 'It', 'was', 'horrible.', 'HORRIBLE!'], 'label': 'neg'}\n",
      "TEXT Vocab Size: 25002\n",
      "LABEL Vocab Size: 2\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))\n",
    "print('TEXT Vocab Size:', len(TEXT.vocab))\n",
    "print('LABEL Vocab Size:',len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Change the output appropriately in ‘Simple Sentiment Analysis.ipynb’ to build an LSTM based language model. Plot the training performance as a function of epochs/iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. For each model, describe the key design choices made. Briefly mention how each choice influences training time and generative quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. For each model, starting with the phrase ”My favorite movie ”, sample the next few words and create a 20 word generated review. Repeat this 5 times (you should ideally get different outputs each time) and report the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
